{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6a1d96b-57d6-41e3-a6f4-ec9828d1fd9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\maria\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\maria\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\maria\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\maria\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\maria\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\maria\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/5\n",
      "WARNING:tensorflow:From C:\\Users\\maria\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\maria\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "217/217 [==============================] - 6s 24ms/step - loss: 0.6763 - accuracy: 0.7081 - val_loss: 0.4837 - val_accuracy: 0.8130\n",
      "Epoch 2/5\n",
      "217/217 [==============================] - 5s 23ms/step - loss: 0.3300 - accuracy: 0.8808 - val_loss: 0.3995 - val_accuracy: 0.8531\n",
      "Epoch 3/5\n",
      "217/217 [==============================] - 5s 22ms/step - loss: 0.1520 - accuracy: 0.9536 - val_loss: 0.3989 - val_accuracy: 0.8670\n",
      "Epoch 4/5\n",
      "217/217 [==============================] - 5s 23ms/step - loss: 0.0801 - accuracy: 0.9777 - val_loss: 0.4446 - val_accuracy: 0.8632\n",
      "Epoch 5/5\n",
      "217/217 [==============================] - 5s 23ms/step - loss: 0.0496 - accuracy: 0.9873 - val_loss: 0.4914 - val_accuracy: 0.8730\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maria\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleRNN - maxlen: 100, split_ratio: 0.2, val_accuracy: 0.8730158805847168\n",
      "Epoch 1/5\n",
      "217/217 [==============================] - 16s 67ms/step - loss: 0.6281 - accuracy: 0.7254 - val_loss: 0.4527 - val_accuracy: 0.8294\n",
      "Epoch 2/5\n",
      "217/217 [==============================] - 14s 62ms/step - loss: 0.3522 - accuracy: 0.8675 - val_loss: 0.3857 - val_accuracy: 0.8595\n",
      "Epoch 3/5\n",
      "217/217 [==============================] - 14s 65ms/step - loss: 0.2592 - accuracy: 0.9126 - val_loss: 0.3805 - val_accuracy: 0.8623\n",
      "Epoch 4/5\n",
      "217/217 [==============================] - 13s 60ms/step - loss: 0.2038 - accuracy: 0.9325 - val_loss: 0.4286 - val_accuracy: 0.8609\n",
      "Epoch 5/5\n",
      "217/217 [==============================] - 13s 60ms/step - loss: 0.1734 - accuracy: 0.9441 - val_loss: 0.4206 - val_accuracy: 0.8724\n",
      "LSTM - maxlen: 100, split_ratio: 0.2, val_accuracy: 0.8724386692047119\n",
      "Epoch 1/5\n",
      "190/190 [==============================] - 6s 26ms/step - loss: 0.7124 - accuracy: 0.6928 - val_loss: 0.5056 - val_accuracy: 0.8085\n",
      "Epoch 2/5\n",
      "190/190 [==============================] - 5s 24ms/step - loss: 0.3712 - accuracy: 0.8624 - val_loss: 0.4437 - val_accuracy: 0.8262\n",
      "Epoch 3/5\n",
      "190/190 [==============================] - 5s 24ms/step - loss: 0.1901 - accuracy: 0.9419 - val_loss: 0.4317 - val_accuracy: 0.8503\n",
      "Epoch 4/5\n",
      "190/190 [==============================] - 5s 24ms/step - loss: 0.0915 - accuracy: 0.9752 - val_loss: 0.4960 - val_accuracy: 0.8422\n",
      "Epoch 5/5\n",
      "190/190 [==============================] - 5s 25ms/step - loss: 0.0518 - accuracy: 0.9876 - val_loss: 0.5640 - val_accuracy: 0.8524\n",
      "SimpleRNN - maxlen: 100, split_ratio: 0.3, val_accuracy: 0.8524148464202881\n",
      "Epoch 1/5\n",
      "190/190 [==============================] - 14s 66ms/step - loss: 0.6403 - accuracy: 0.7187 - val_loss: 0.4475 - val_accuracy: 0.8266\n",
      "Epoch 2/5\n",
      "190/190 [==============================] - 12s 64ms/step - loss: 0.3563 - accuracy: 0.8694 - val_loss: 0.4342 - val_accuracy: 0.8287\n",
      "Epoch 3/5\n",
      "190/190 [==============================] - 13s 66ms/step - loss: 0.2547 - accuracy: 0.9122 - val_loss: 0.4189 - val_accuracy: 0.8480\n",
      "Epoch 4/5\n",
      "190/190 [==============================] - 13s 66ms/step - loss: 0.2020 - accuracy: 0.9340 - val_loss: 0.4709 - val_accuracy: 0.8363\n",
      "Epoch 5/5\n",
      "190/190 [==============================] - 12s 62ms/step - loss: 0.1659 - accuracy: 0.9463 - val_loss: 0.4738 - val_accuracy: 0.8561\n",
      "LSTM - maxlen: 100, split_ratio: 0.3, val_accuracy: 0.8560708165168762\n",
      "Epoch 1/5\n",
      "163/163 [==============================] - 5s 26ms/step - loss: 0.7266 - accuracy: 0.6765 - val_loss: 0.5052 - val_accuracy: 0.8059\n",
      "Epoch 2/5\n",
      "163/163 [==============================] - 4s 26ms/step - loss: 0.3410 - accuracy: 0.8790 - val_loss: 0.4291 - val_accuracy: 0.8476\n",
      "Epoch 3/5\n",
      "163/163 [==============================] - 4s 26ms/step - loss: 0.1524 - accuracy: 0.9529 - val_loss: 0.4991 - val_accuracy: 0.8296\n",
      "Epoch 4/5\n",
      "163/163 [==============================] - 4s 27ms/step - loss: 0.0706 - accuracy: 0.9809 - val_loss: 0.5340 - val_accuracy: 0.8408\n",
      "Epoch 5/5\n",
      "163/163 [==============================] - 4s 27ms/step - loss: 0.0366 - accuracy: 0.9912 - val_loss: 0.6115 - val_accuracy: 0.8398\n",
      "SimpleRNN - maxlen: 100, split_ratio: 0.4, val_accuracy: 0.847597062587738\n",
      "Epoch 1/5\n",
      "163/163 [==============================] - 13s 70ms/step - loss: 0.6579 - accuracy: 0.7131 - val_loss: 0.4696 - val_accuracy: 0.8184\n",
      "Epoch 2/5\n",
      "163/163 [==============================] - 11s 66ms/step - loss: 0.3620 - accuracy: 0.8665 - val_loss: 0.4237 - val_accuracy: 0.8492\n",
      "Epoch 3/5\n",
      "163/163 [==============================] - 11s 68ms/step - loss: 0.2551 - accuracy: 0.9132 - val_loss: 0.4309 - val_accuracy: 0.8492\n",
      "Epoch 4/5\n",
      "163/163 [==============================] - 11s 66ms/step - loss: 0.1982 - accuracy: 0.9333 - val_loss: 0.4846 - val_accuracy: 0.8463\n",
      "Epoch 5/5\n",
      "163/163 [==============================] - 11s 65ms/step - loss: 0.1630 - accuracy: 0.9488 - val_loss: 0.4958 - val_accuracy: 0.8480\n",
      "LSTM - maxlen: 100, split_ratio: 0.4, val_accuracy: 0.8491845726966858\n",
      "Epoch 1/5\n",
      "217/217 [==============================] - 7s 28ms/step - loss: 0.6463 - accuracy: 0.7291 - val_loss: 0.4372 - val_accuracy: 0.8401\n",
      "Epoch 2/5\n",
      "217/217 [==============================] - 6s 27ms/step - loss: 0.2907 - accuracy: 0.9005 - val_loss: 0.4001 - val_accuracy: 0.8517\n",
      "Epoch 3/5\n",
      "217/217 [==============================] - 6s 28ms/step - loss: 0.1954 - accuracy: 0.9348 - val_loss: 0.4682 - val_accuracy: 0.8127\n",
      "Epoch 4/5\n",
      "217/217 [==============================] - 7s 31ms/step - loss: 0.1805 - accuracy: 0.9396 - val_loss: 0.6700 - val_accuracy: 0.7801\n",
      "Epoch 5/5\n",
      "217/217 [==============================] - 7s 32ms/step - loss: 0.0885 - accuracy: 0.9727 - val_loss: 0.4939 - val_accuracy: 0.8675\n",
      "SimpleRNN - maxlen: 150, split_ratio: 0.2, val_accuracy: 0.86753249168396\n",
      "Epoch 1/5\n",
      "217/217 [==============================] - 37s 160ms/step - loss: 0.6159 - accuracy: 0.7358 - val_loss: 0.4165 - val_accuracy: 0.8401\n",
      "Epoch 2/5\n",
      "217/217 [==============================] - 35s 161ms/step - loss: 0.3412 - accuracy: 0.8739 - val_loss: 0.3810 - val_accuracy: 0.8574\n",
      "Epoch 3/5\n",
      "217/217 [==============================] - 35s 161ms/step - loss: 0.2516 - accuracy: 0.9137 - val_loss: 0.3927 - val_accuracy: 0.8548\n",
      "Epoch 4/5\n",
      "217/217 [==============================] - 33s 152ms/step - loss: 0.2013 - accuracy: 0.9331 - val_loss: 0.4337 - val_accuracy: 0.8540\n",
      "Epoch 5/5\n",
      "217/217 [==============================] - 33s 151ms/step - loss: 0.1710 - accuracy: 0.9449 - val_loss: 0.4309 - val_accuracy: 0.8701\n",
      "LSTM - maxlen: 150, split_ratio: 0.2, val_accuracy: 0.8701298832893372\n",
      "Epoch 1/5\n",
      "190/190 [==============================] - 9s 45ms/step - loss: 0.6434 - accuracy: 0.7262 - val_loss: 0.4514 - val_accuracy: 0.8272\n",
      "Epoch 2/5\n",
      "190/190 [==============================] - 8s 43ms/step - loss: 0.3021 - accuracy: 0.8951 - val_loss: 0.4322 - val_accuracy: 0.8376\n",
      "Epoch 3/5\n",
      "190/190 [==============================] - 8s 43ms/step - loss: 0.1689 - accuracy: 0.9467 - val_loss: 0.4474 - val_accuracy: 0.8559\n",
      "Epoch 4/5\n",
      "190/190 [==============================] - 9s 46ms/step - loss: 0.0814 - accuracy: 0.9785 - val_loss: 0.4924 - val_accuracy: 0.8528\n",
      "Epoch 5/5\n",
      "190/190 [==============================] - 10s 53ms/step - loss: 0.0423 - accuracy: 0.9909 - val_loss: 0.5548 - val_accuracy: 0.8493\n",
      "SimpleRNN - maxlen: 150, split_ratio: 0.3, val_accuracy: 0.8558784127235413\n",
      "Epoch 1/5\n",
      "190/190 [==============================] - 25s 124ms/step - loss: 0.6378 - accuracy: 0.7229 - val_loss: 0.4654 - val_accuracy: 0.8149\n",
      "Epoch 2/5\n",
      "190/190 [==============================] - 23s 123ms/step - loss: 0.3523 - accuracy: 0.8703 - val_loss: 0.4039 - val_accuracy: 0.8493\n",
      "Epoch 3/5\n",
      "190/190 [==============================] - 24s 126ms/step - loss: 0.2516 - accuracy: 0.9154 - val_loss: 0.4437 - val_accuracy: 0.8505\n",
      "Epoch 4/5\n",
      "190/190 [==============================] - 24s 125ms/step - loss: 0.1962 - accuracy: 0.9358 - val_loss: 0.4523 - val_accuracy: 0.8561\n",
      "Epoch 5/5\n",
      "190/190 [==============================] - 25s 132ms/step - loss: 0.1609 - accuracy: 0.9484 - val_loss: 0.4881 - val_accuracy: 0.8563\n",
      "LSTM - maxlen: 150, split_ratio: 0.3, val_accuracy: 0.8562632203102112\n",
      "Epoch 1/5\n",
      "163/163 [==============================] - 9s 51ms/step - loss: 0.7351 - accuracy: 0.6722 - val_loss: 0.5356 - val_accuracy: 0.7890\n",
      "Epoch 2/5\n",
      "163/163 [==============================] - 8s 47ms/step - loss: 0.3426 - accuracy: 0.8779 - val_loss: 0.4417 - val_accuracy: 0.8345\n",
      "Epoch 3/5\n",
      "163/163 [==============================] - 7s 43ms/step - loss: 0.1645 - accuracy: 0.9501 - val_loss: 0.4856 - val_accuracy: 0.8382\n",
      "Epoch 4/5\n",
      "163/163 [==============================] - 7s 43ms/step - loss: 0.0921 - accuracy: 0.9723 - val_loss: 0.5190 - val_accuracy: 0.8434\n",
      "Epoch 5/5\n",
      "163/163 [==============================] - 7s 44ms/step - loss: 0.0557 - accuracy: 0.9864 - val_loss: 0.5883 - val_accuracy: 0.8395\n",
      "SimpleRNN - maxlen: 150, split_ratio: 0.4, val_accuracy: 0.8434117436408997\n",
      "Epoch 1/5\n",
      "163/163 [==============================] - 21s 122ms/step - loss: 0.6653 - accuracy: 0.7119 - val_loss: 0.4790 - val_accuracy: 0.8101\n",
      "Epoch 2/5\n",
      "163/163 [==============================] - 19s 118ms/step - loss: 0.3745 - accuracy: 0.8610 - val_loss: 0.4240 - val_accuracy: 0.8392\n",
      "Epoch 3/5\n",
      "163/163 [==============================] - 19s 117ms/step - loss: 0.2613 - accuracy: 0.9103 - val_loss: 0.4255 - val_accuracy: 0.8459\n",
      "Epoch 4/5\n",
      "163/163 [==============================] - 19s 118ms/step - loss: 0.2024 - accuracy: 0.9298 - val_loss: 0.4499 - val_accuracy: 0.8526\n",
      "Epoch 5/5\n",
      "163/163 [==============================] - 20s 120ms/step - loss: 0.1581 - accuracy: 0.9501 - val_loss: 0.5110 - val_accuracy: 0.8473\n",
      "LSTM - maxlen: 150, split_ratio: 0.4, val_accuracy: 0.8526483178138733\n",
      "Epoch 1/5\n",
      "217/217 [==============================] - 15s 65ms/step - loss: 0.6648 - accuracy: 0.7176 - val_loss: 0.4478 - val_accuracy: 0.8271\n",
      "Epoch 2/5\n",
      "217/217 [==============================] - 14s 63ms/step - loss: 0.3480 - accuracy: 0.8762 - val_loss: 0.4320 - val_accuracy: 0.8401\n",
      "Epoch 3/5\n",
      "217/217 [==============================] - 14s 63ms/step - loss: 0.2391 - accuracy: 0.9214 - val_loss: 0.4061 - val_accuracy: 0.8615\n",
      "Epoch 4/5\n",
      "217/217 [==============================] - 14s 64ms/step - loss: 0.1189 - accuracy: 0.9654 - val_loss: 0.4433 - val_accuracy: 0.8629\n",
      "Epoch 5/5\n",
      "217/217 [==============================] - 14s 67ms/step - loss: 0.0626 - accuracy: 0.9846 - val_loss: 0.4784 - val_accuracy: 0.8684\n",
      "SimpleRNN - maxlen: 313, split_ratio: 0.2, val_accuracy: 0.8683982491493225\n",
      "Epoch 1/5\n",
      "217/217 [==============================] - 57s 257ms/step - loss: 0.6020 - accuracy: 0.7421 - val_loss: 0.4175 - val_accuracy: 0.8447\n",
      "Epoch 2/5\n",
      "217/217 [==============================] - 68s 314ms/step - loss: 0.3376 - accuracy: 0.8770 - val_loss: 0.3622 - val_accuracy: 0.8667\n",
      "Epoch 3/5\n",
      "217/217 [==============================] - 71s 328ms/step - loss: 0.2477 - accuracy: 0.9150 - val_loss: 0.3781 - val_accuracy: 0.8727\n",
      "Epoch 4/5\n",
      "217/217 [==============================] - 83s 385ms/step - loss: 0.2001 - accuracy: 0.9332 - val_loss: 0.3968 - val_accuracy: 0.8750\n",
      "Epoch 5/5\n",
      "217/217 [==============================] - 81s 374ms/step - loss: 0.1666 - accuracy: 0.9438 - val_loss: 0.4390 - val_accuracy: 0.8678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maria\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM - maxlen: 313, split_ratio: 0.2, val_accuracy: 0.8750360608100891\n",
      "Epoch 1/5\n",
      "190/190 [==============================] - 19s 95ms/step - loss: 0.6686 - accuracy: 0.7114 - val_loss: 0.4820 - val_accuracy: 0.8141\n",
      "Epoch 2/5\n",
      "190/190 [==============================] - 17s 92ms/step - loss: 0.3131 - accuracy: 0.8938 - val_loss: 0.4175 - val_accuracy: 0.8449\n",
      "Epoch 3/5\n",
      "190/190 [==============================] - 18s 93ms/step - loss: 0.1349 - accuracy: 0.9587 - val_loss: 0.4730 - val_accuracy: 0.8413\n",
      "Epoch 4/5\n",
      "190/190 [==============================] - 17s 92ms/step - loss: 0.1705 - accuracy: 0.9621 - val_loss: 2.3924 - val_accuracy: 0.4070\n",
      "Epoch 5/5\n",
      "190/190 [==============================] - 18s 93ms/step - loss: 0.6347 - accuracy: 0.7606 - val_loss: 0.5176 - val_accuracy: 0.8147\n",
      "SimpleRNN - maxlen: 313, split_ratio: 0.3, val_accuracy: 0.8449105024337769\n",
      "Epoch 1/5\n",
      "190/190 [==============================] - 73s 377ms/step - loss: 0.6301 - accuracy: 0.7366 - val_loss: 0.4556 - val_accuracy: 0.8137\n",
      "Epoch 2/5\n",
      "190/190 [==============================] - 67s 356ms/step - loss: 0.3519 - accuracy: 0.8690 - val_loss: 0.3976 - val_accuracy: 0.8528\n",
      "Epoch 3/5\n",
      "190/190 [==============================] - 68s 359ms/step - loss: 0.2852 - accuracy: 0.8966 - val_loss: 0.6448 - val_accuracy: 0.7185\n",
      "Epoch 4/5\n",
      "190/190 [==============================] - 70s 367ms/step - loss: 0.2414 - accuracy: 0.9149 - val_loss: 0.4406 - val_accuracy: 0.8580\n",
      "Epoch 5/5\n",
      "190/190 [==============================] - 70s 371ms/step - loss: 0.1715 - accuracy: 0.9442 - val_loss: 0.4671 - val_accuracy: 0.8538\n",
      "LSTM - maxlen: 313, split_ratio: 0.3, val_accuracy: 0.8579949736595154\n",
      "Epoch 1/5\n",
      "163/163 [==============================] - 20s 115ms/step - loss: 0.6914 - accuracy: 0.7005 - val_loss: 0.4867 - val_accuracy: 0.8119\n",
      "Epoch 2/5\n",
      "163/163 [==============================] - 18s 111ms/step - loss: 0.3998 - accuracy: 0.8538 - val_loss: 0.4272 - val_accuracy: 0.8421\n",
      "Epoch 3/5\n",
      "163/163 [==============================] - 15s 95ms/step - loss: 0.2696 - accuracy: 0.9085 - val_loss: 0.4305 - val_accuracy: 0.8431\n",
      "Epoch 4/5\n",
      "163/163 [==============================] - 14s 88ms/step - loss: 0.1628 - accuracy: 0.9503 - val_loss: 0.4961 - val_accuracy: 0.8420\n",
      "Epoch 5/5\n",
      "163/163 [==============================] - 14s 89ms/step - loss: 0.0924 - accuracy: 0.9754 - val_loss: 0.5053 - val_accuracy: 0.8508\n",
      "SimpleRNN - maxlen: 313, split_ratio: 0.4, val_accuracy: 0.8507721424102783\n",
      "Epoch 1/5\n",
      "163/163 [==============================] - 60s 356ms/step - loss: 0.6685 - accuracy: 0.7078 - val_loss: 0.4705 - val_accuracy: 0.8135\n",
      "Epoch 2/5\n",
      "163/163 [==============================] - 59s 365ms/step - loss: 0.3585 - accuracy: 0.8674 - val_loss: 0.4213 - val_accuracy: 0.8464\n",
      "Epoch 3/5\n",
      "163/163 [==============================] - 60s 366ms/step - loss: 0.2559 - accuracy: 0.9115 - val_loss: 0.4417 - val_accuracy: 0.8488\n",
      "Epoch 4/5\n",
      "163/163 [==============================] - 63s 385ms/step - loss: 0.1962 - accuracy: 0.9344 - val_loss: 0.4620 - val_accuracy: 0.8482\n",
      "Epoch 5/5\n",
      "163/163 [==============================] - 60s 369ms/step - loss: 0.1550 - accuracy: 0.9501 - val_loss: 0.5414 - val_accuracy: 0.8399\n",
      "LSTM - maxlen: 313, split_ratio: 0.4, val_accuracy: 0.8487516045570374\n",
      "Best parameters for SimpleRNN: {'maxlen': 100, 'split_ratio': 0.2}\n",
      "Best parameters for LSTM: {'maxlen': 313, 'split_ratio': 0.2}\n",
      "Best accuracy for SimpleRNN: 0.8730158805847168\n",
      "Best accuracy for LSTM: 0.8750360608100891\n",
      "SimpleRNN summary\n",
      "   maxlen  split_ratio  Accuracy\n",
      "0     100          0.2  0.873016\n",
      "1     100          0.3  0.852415\n",
      "2     100          0.4  0.847597\n",
      "3     150          0.2  0.867532\n",
      "4     150          0.3  0.855878\n",
      "5     150          0.4  0.843412\n",
      "6     313          0.2  0.868398\n",
      "7     313          0.3  0.844911\n",
      "8     313          0.4  0.850772\n",
      "LSTM summary\n",
      "   maxlen  split_ratio  Accuracy\n",
      "0     100          0.2  0.872439\n",
      "1     100          0.3  0.856071\n",
      "2     100          0.4  0.849185\n",
      "3     150          0.2  0.870130\n",
      "4     150          0.3  0.856263\n",
      "5     150          0.4  0.852648\n",
      "6     313          0.2  0.875036\n",
      "7     313          0.3  0.857995\n",
      "8     313          0.4  0.848752\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Embedding, SimpleRNN, LSTM, Dense, concatenate, Input\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "\n",
    "data = pd.read_csv(\"amazon_reviews.csv\")\n",
    "\n",
    "# Drop missing values\n",
    "data.replace(' ', pd.NA, inplace=True)\n",
    "data = data.dropna()\n",
    "\n",
    "# stopwords and lemmatizer\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# data preprocessing\n",
    "def data_preprocessing(row):\n",
    "    row = re.sub(r'[^a-zA-Z\\s]', '', row.lower())\n",
    "    tokens = word_tokenize(row)\n",
    "    clean_rows = []\n",
    "    for token in tokens:\n",
    "        if token not in stop_words:\n",
    "            clean_token = lemmatizer.lemmatize(token)\n",
    "            clean_rows.append(clean_token)\n",
    "    clean_row = ' '.join(clean_rows)\n",
    "    return clean_row\n",
    "\n",
    "# Apply data preprocessing to cleaned_review column\n",
    "data['cleaned_review'] = data['cleaned_review'].apply(data_preprocessing)\n",
    "# Update cleaned_review_length column\n",
    "data['cleaned_review_length'] = data['cleaned_review'].apply(lambda x: len(x.split()))\n",
    "\n",
    "# hyperparameters maxlen values and split ratios \n",
    "maxlength = max(data['cleaned_review_length'])\n",
    "maxlen_values = [100, 150, maxlength]\n",
    "split_ratios = [0.2, 0.3, 0.4]\n",
    "# list to append results of each model\n",
    "results_SimpleRNN = []\n",
    "results_LSTM = []\n",
    "\n",
    "best_accuracy_simple_rnn = 0\n",
    "best_accuracy_lstm = 0\n",
    "best_parameters_simple_rnn = {}\n",
    "best_parameters_lstm = {}\n",
    "\n",
    "for maxlen in maxlen_values:\n",
    "    for split_ratio in split_ratios:\n",
    "        # Split data\n",
    "        X_train, X_test, y_train, y_test = train_test_split(data['cleaned_review'], data['sentiments'], test_size=split_ratio, random_state=42)\n",
    "\n",
    "        # Tokenization\n",
    "        tokenizer = Tokenizer()\n",
    "        tokenizer.fit_on_texts(X_train)\n",
    "        X_train_text = tokenizer.texts_to_sequences(X_train)\n",
    "        X_test_text = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "        vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "        # Encoding the target variable\n",
    "        encoder = LabelEncoder()\n",
    "        y_train_encoded = encoder.fit_transform(y_train)\n",
    "        y_test_encoded = encoder.transform(y_test)\n",
    "\n",
    "        # Padding (same length)\n",
    "        X_train_text_padded = pad_sequences(X_train_text, maxlen=maxlen)\n",
    "        X_test_text_padded = pad_sequences(X_test_text, maxlen=maxlen)\n",
    "\n",
    "        # Define input layer\n",
    "        model_simple_rnn_input_text = Input(shape=(maxlen,))\n",
    "        # Embedding layer\n",
    "        embedding_layer_simple_rnn = Embedding(vocab_size, 100, input_length=maxlen)(model_simple_rnn_input_text)\n",
    "        # SimpleRNN layer\n",
    "        simple_rnn_layer = SimpleRNN(100)(embedding_layer_simple_rnn)\n",
    "        # Output layer\n",
    "        output_simple_rnn = Dense(3, activation='softmax')(simple_rnn_layer)\n",
    "        # Define model\n",
    "        model_simple_rnn = Model(inputs=model_simple_rnn_input_text, outputs=output_simple_rnn)\n",
    "        # Compile the model\n",
    "        model_simple_rnn.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "        # Train the model\n",
    "        history_simple_rnn = model_simple_rnn.fit(X_train_text_padded, y_train_encoded, validation_data=(X_test_text_padded, y_test_encoded), epochs=5, batch_size=64, verbose=1)\n",
    "\n",
    "        # Check if the current model is better than the previous best\n",
    "        val_accuracy_simple_rnn = max(history_simple_rnn.history['val_accuracy'])\n",
    "        if val_accuracy_simple_rnn > best_accuracy_simple_rnn:\n",
    "            best_accuracy_simple_rnn = val_accuracy_simple_rnn\n",
    "            best_parameters_simple_rnn = {'maxlen': maxlen, 'split_ratio': split_ratio}\n",
    "            # Save the best SimpleRNN model\n",
    "            model_simple_rnn.save(f\"best_model_simple_rnn.h5\")\n",
    "\n",
    "        results_SimpleRNN.append([maxlen,split_ratio,val_accuracy_simple_rnn])\n",
    "\n",
    "        # accuracy for SimpleRNN\n",
    "        print(f\"SimpleRNN - maxlen: {maxlen}, split_ratio: {split_ratio}, val_accuracy: {val_accuracy_simple_rnn}\")\n",
    "\n",
    "        # Define input layer\n",
    "        model_lstm_input_text = Input(shape=(maxlen,))\n",
    "        # Embedding layer\n",
    "        embedding_layer_lstm = Embedding(vocab_size, 100, input_length=maxlen)(model_lstm_input_text)\n",
    "        # LSTM layer\n",
    "        lstm_layer = LSTM(100)(embedding_layer_lstm)\n",
    "        # Output layer\n",
    "        output_lstm = Dense(3, activation='softmax')(lstm_layer)\n",
    "        # Define model\n",
    "        model_lstm = Model(inputs=model_lstm_input_text, outputs=output_lstm)\n",
    "        # Compile the model\n",
    "        model_lstm.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "        # Train the model\n",
    "        history_lstm = model_lstm.fit(X_train_text_padded, y_train_encoded, validation_data=(X_test_text_padded, y_test_encoded), epochs=5, batch_size=64, verbose=1)\n",
    "\n",
    "        # Check if the current model is better than the previous best\n",
    "        val_accuracy_lstm = max(history_lstm.history['val_accuracy'])\n",
    "        if val_accuracy_lstm > best_accuracy_lstm:\n",
    "            best_accuracy_lstm = val_accuracy_lstm\n",
    "            best_parameters_lstm = {'maxlen': maxlen, 'split_ratio': split_ratio}\n",
    "            # Save the best LSTM model\n",
    "            model_lstm.save(f\"best_model_lstm.h5\")\n",
    "\n",
    "        results_LSTM.append([maxlen, split_ratio, val_accuracy_lstm])\n",
    "\n",
    "        # accuracy for LSTM\n",
    "        print(f\"LSTM - maxlen: {maxlen}, split_ratio: {split_ratio}, val_accuracy: {val_accuracy_lstm}\")\n",
    "\n",
    "# best parameters for SimpleRNN and LSTM\n",
    "print(\"Best parameters for SimpleRNN:\", best_parameters_simple_rnn)\n",
    "print(\"Best parameters for LSTM:\", best_parameters_lstm)\n",
    "\n",
    "# best accuracy for SimpleRNN and LSTM\n",
    "print(\"Best accuracy for SimpleRNN:\", best_accuracy_simple_rnn)\n",
    "print(\"Best accuracy for LSTM:\", best_accuracy_lstm)\n",
    "\n",
    "# model summary of each model and the best hyperparameters\n",
    "results_SimpleRNN_df = pd.DataFrame(results_SimpleRNN, columns=['maxlen', 'split_ratio', 'Accuracy'])\n",
    "results_LSTM_df = pd.DataFrame(results_LSTM, columns=['maxlen', 'split_ratio', 'Accuracy'])\n",
    "print ('SimpleRNN summary')\n",
    "print(results_SimpleRNN_df)\n",
    "print ('LSTM summary')\n",
    "print(results_LSTM_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3da832b2-41e7-47cc-a3c6-43d8b0bccf15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your review:  perfect little mouse this mouse is so easy to use and to charge up it lightweight love the little colors and it fits my hand perfectly\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 153ms/step\n",
      "Predicted sentiment SimpleRNN: positive\n",
      "1/1 [==============================] - 0s 353ms/step\n",
      "Predicted sentiment LSTM: positive\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Load the best SimpleRNN model\n",
    "best_model_simple_rnn = tf.keras.models.load_model(\"best_model_simple_rnn.h5\")\n",
    "# Load the best LSTM model\n",
    "best_model_lstm = tf.keras.models.load_model(\"best_model_lstm.h5\")\n",
    "\n",
    "# User input for a new review\n",
    "new_review = input(\"Enter your review: \")\n",
    "# Preprocess the new review\n",
    "cleaned_review = data_preprocessing(new_review)\n",
    "# Tokenize\n",
    "new_review_sequence = tokenizer.texts_to_sequences([cleaned_review])\n",
    "\n",
    "# Pad the new review simple_rnn\n",
    "new_review_padded = pad_sequences(new_review_sequence, maxlen=best_parameters_simple_rnn['maxlen'])\n",
    "# Predict using the best SimpleRNN model\n",
    "predicted_sentiment_SimpleRNN = best_model_simple_rnn.predict(new_review_padded)\n",
    "# Decode the predicted sentiment\n",
    "predicted_sentiment_label_SimpleRNN = encoder.classes_[np.argmax(predicted_sentiment_SimpleRNN)]\n",
    "print(\"Predicted sentiment SimpleRNN:\", predicted_sentiment_label_SimpleRNN)\n",
    "\n",
    "# Pad the new review lstm\n",
    "new_review_padded = pad_sequences(new_review_sequence, maxlen=best_parameters_lstm['maxlen'])\n",
    "# Predict the sentiment of the new review using the best LSTM model\n",
    "predicted_sentiment_LSTM = best_model_lstm.predict(new_review_padded)\n",
    "# Decode the predicted sentiment\n",
    "predicted_sentiment_label_LSTM = encoder.classes_[np.argmax(predicted_sentiment_LSTM)]\n",
    "print(\"Predicted sentiment LSTM:\", predicted_sentiment_label_LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ee8ad1-5b5b-4523-a0d5-2021f3fd8321",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
